---
title: 'Quickstart'
description: 'Create and test a prompt in 5 minutes'
---

## ðŸ“˜ Quickstart Guide

### In this quickstart we will create a prompt for classifying online reviews of movies as either `positive` or `negative`.

---

### 1. Create Your First Prompt

- Navigate to Prompt list page ([https://app.asserto.ai/app/prompt](https://app.asserto.ai/app/prompt))
- Set name to `Movie Review Sentiment`

You will see the Prompt Development Dashboard.

---

### 2. Define the Prompt

In the left panel of the dashboard, you can define the messages that make up the prompt.

#### Step 1: `system` message

Define the LLM's role and instructions. Specify the expected output format to make the response machine-readable.

```plaintext
You are a sentiment classifier.  
Classify the following movie review as 'positive' or 'negative'.  

Respond in JSON format:  
{"sentiment": "<result>"}
```

#### Step 2: `user` message

Write a template for the user input using a placeholder for the review text.

Templates use Mustache syntax â€” wrap parameter names in double curly braces (`{{ }}`).

```mustache
Review: {{review}}
```

---

### 3. Configure the Prompt

In the right-side panel, go to the **Config** tab. Here you'll configure how the LLM runs and define the inputs and outputs.

#### Step 1: Model Configuration

- Select a model (e.g., `gpt-4`, `claude`, etc.)
- Set temperature to `0` for consistent deterministic outputs
- Ensure **response format** is set to `JSON`

#### Step 2: Define Prompt Parameters

- Add a parameter named `review`
- Set its **type** to `text` to allow multi-line input
- This corresponds to the `{{review}}` placeholder in your prompt

#### Step 3: Define the Output Schema

- Add a result field named `sentiment`
- This matches the key in the expected LLM JSON response
- Used for validation and test automation

---

### 4. Try it Out with Playground

On the right-side panel, switch to the **Playground** tab.

Here you can run quick tests, inspect the LLM response, and make prompt edits.

#### Step 1: Add Sample Input

Provide a test value for the `review` parameter. For example:

**Positive review**
```json
{
  "review": "A visually stunning masterpiece with a moving story and brilliant acting."
}
```

#### Step 2: Run and Inspect

- Click **Submit**
- Review the output JSON response
- Iterate on prompt instructions if necessary for better accuracy

#### Step 3: Repeat with Another Input

Try different inputs to validate how well the prompt handles variations.

**Negative review**
```json
{
  "review": "The plot was confusing, the pacing was terrible, and the acting was wooden."
}
```

